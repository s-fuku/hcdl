{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "rc('font', **{'family' : \"sans-serif\"})\n",
    "params = {'text.latex.preamble' : [r'\\usepackage{siunitx}', r'\\usepackage{amsmath}']}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.special import loggamma\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from rpy2.robjects import numpy2ri\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.resetwarnings()\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = np.finfo(np.float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = './data'\n",
    "outdir = './output'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R packages\n",
    "## blockmodels\n",
    "blockmodels = importr(\"blockmodels\")\n",
    "## label.switching\n",
    "label_switching = importr(\"label.switching\")\n",
    "## base\n",
    "base = importr(\"base\")\n",
    "\n",
    "dollar = base.__dict__[\"$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize = 10000)\n",
    "def normterm_discrete(n, k):\n",
    "    if n == 1:\n",
    "        return np.log(k)\n",
    "    if k == 1:\n",
    "        return 1.0\n",
    "    elif k == 2:\n",
    "        return np.sum(sorted([ np.exp(loggamma(n+1) - loggamma(t+1) - loggamma(n-t+1) + \n",
    "                               t*(np.log(t) - np.log(n)) + (n-t)*(np.log(n-t) - np.log(n))\n",
    "                        )\n",
    "                        for t in range(1, n)]))\n",
    "    else:\n",
    "        return normterm_discrete(n, k-1) + n/(k-2) * normterm_discrete(n, k-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_latent_index_variable(z):\n",
    "    unique_z = sorted(np.unique(z))\n",
    "    if len(unique_z) == np.max(z) + 1:\n",
    "        return z\n",
    "    new_z = np.zeros(z.shape, dtype=np.int)\n",
    "    for index, current in enumerate(unique_z):\n",
    "        new_z[z == current] = index\n",
    "    return new_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dnml(X, Z1, Z2, K=3, L=3):    \n",
    "    N = X.shape[0]\n",
    "    \n",
    "    codelen_x_z = 0.0\n",
    "    codelen_z = 0.0\n",
    "\n",
    "    for k in range(K):\n",
    "        for l in range(L):\n",
    "            n_pos = np.sum(X[Z1 == k, :][:, Z2 == l] == 1)\n",
    "            n_neg = np.sum(X[Z1 == k, :][:, Z2 == l] == 0)\n",
    "            n_all = n_pos + n_neg\n",
    "\n",
    "            if n_all >=2:\n",
    "                codelen_x_z += n_all * np.log(n_all)\n",
    "                codelen_x_z += np.log(normterm_discrete(n_all, 2))\n",
    "            \n",
    "            if n_pos >=2:\n",
    "                codelen_x_z -= n_pos * np.log(n_pos)\n",
    "            if n_neg >=2:\n",
    "                codelen_x_z -= n_neg * np.log(n_neg)\n",
    "            \n",
    "        n_k = np.sum(Z1 == k)\n",
    "        if n_k >= 1:\n",
    "            codelen_z += n_k * (np.log(N) - np.log(n_k))\n",
    "\n",
    "    codelen_z += np.log(normterm_discrete(N, K))\n",
    "    \n",
    "    codelen = codelen_x_z + codelen_z\n",
    "\n",
    "    return codelen, codelen_x_z, codelen_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dnml_by_prob(X, Z, alpha, theta, K=3, L=3, eps=1e-12):    \n",
    "    N = X.shape[0]\n",
    "    \n",
    "    Z1 = np.argmax(Z, axis=1)\n",
    "    \n",
    "    Z1 = check_latent_index_variable(Z1)\n",
    "    Z2 = Z1\n",
    "    \n",
    "    codelen_x_z = 0.0\n",
    "    codelen_z = 0.0\n",
    "        \n",
    "    for k in range(K):\n",
    "        for l in range(L):\n",
    "            n_pos = np.sum(X[Z1 == k, :][:, Z2 == l] == 1)\n",
    "            n_neg = np.sum(X[Z1 == k, :][:, Z2 == l] == 0)\n",
    "            n_all = n_pos + n_neg\n",
    "            \n",
    "            if theta[k, l] < eps:\n",
    "                theta[k, l] = eps\n",
    "            \n",
    "            if theta[k, l] > 1.0 - eps:\n",
    "                theta[k, l] = 1.0 - eps\n",
    "            \n",
    "            codelen_x_z += -n_pos * np.log(theta[k, l]) - n_neg * np.log(1.0 - theta[k, l])\n",
    "            \n",
    "            if n_all >=2:\n",
    "                codelen_x_z += np.log(normterm_discrete(n_all, 2))\n",
    "    \n",
    "        n_k = np.sum(Z1 == k)\n",
    "        codelen_z += -n_k * np.log(alpha[k])\n",
    "\n",
    "    codelen_z += np.log(normterm_discrete(N, K))\n",
    "\n",
    "    codelen = codelen_x_z + codelen_z\n",
    "\n",
    "    return codelen, codelen_x_z, codelen_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loglik_by_prob(X, Z, alpha, theta, K=3, L=3, eps=1e-12):    \n",
    "    N = X.shape[0]\n",
    "    \n",
    "    Z1 = np.argmax(Z, axis=1)\n",
    "    \n",
    "    Z1 = check_latent_index_variable(Z1)\n",
    "    Z2 = Z1\n",
    "    \n",
    "    loglik_x_z = 0.0\n",
    "    loglik_z = 0.0\n",
    "        \n",
    "    for k in range(K):\n",
    "        for l in range(L):\n",
    "            n_pos = np.sum(X[Z1 == k, :][:, Z2 == l] == 1)\n",
    "            n_neg = np.sum(X[Z1 == k, :][:, Z2 == l] == 0)\n",
    "            n_all = n_pos + n_neg\n",
    "            \n",
    "            if theta[k, l] < eps:\n",
    "                theta[k, l] = eps\n",
    "            \n",
    "            if theta[k, l] > 1.0 - eps:\n",
    "                theta[k, l] = 1.0 - eps\n",
    "            \n",
    "            loglik_x_z += -n_pos * np.log(theta[k, l]) - n_neg * np.log(1.0 - theta[k, l])\n",
    "                \n",
    "        n_k = np.sum(Z1 == k)\n",
    "        loglik_z += -n_k * np.log(alpha[k])\n",
    "\n",
    "    loglik = loglik_x_z + loglik_z\n",
    "\n",
    "    return loglik, loglik_x_z, loglik_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lsc(X, Z1, Z2, K=3, L=3):    \n",
    "    codelen = 0.0\n",
    "    N = X.shape[0]\n",
    "\n",
    "    for k in range(K):\n",
    "        for l in range(L):\n",
    "            n_pos = np.sum(X[Z1 == k, :][:, Z2 == l] == 1)\n",
    "            n_neg = np.sum(X[Z1 == k, :][:, Z2 == l] == 0)\n",
    "            n_all = n_pos + n_neg\n",
    "\n",
    "            if n_all >=2:\n",
    "                codelen += n_all * np.log(n_all)\n",
    "            \n",
    "            if n_pos >=2:\n",
    "                codelen -= n_pos * np.log(n_pos)\n",
    "            if n_neg >=2:\n",
    "                codelen -= n_neg * np.log(n_neg)\n",
    "\n",
    "        n_k = np.sum(Z1 == k)\n",
    "        if n_k >= 1:\n",
    "            codelen += n_k * (np.log(N) - np.log(n_k))\n",
    "\n",
    "        codelen += (k + (k+1)*(k+2))/2 * np.log(N/(2.0*np.pi)) -(k+1)/2 * np.log(2.0) + \\\n",
    "           (k+1) * loggamma((k+3)/2) - loggamma((k+1)*(k+3)/2) + (k+1)*(k+2)/2 * np.log(np.pi)\n",
    "\n",
    "    return codelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(X, #z, \n",
    "               scores, scores_f, scores_l, h, delta, K=10):\n",
    "    scores = np.array(scores)\n",
    "    scores_f = np.array(scores_f)\n",
    "    scores_l = np.array(scores_l)\n",
    "    \n",
    "    K = scores.shape[2]\n",
    "    N_trial = scores.shape[0]\n",
    "    T = scores.shape[1]\n",
    "    \n",
    "    codelens = np.array([ codelen_integer(k) for k in range(1, K+1)])\n",
    "    \n",
    "    idxes_all = np.argmin(scores + np.tile(codelens[np.newaxis, np.newaxis], (N_trial, T, 1))[0, 0, :], axis=2)\n",
    "    \n",
    "    models_estimated = np.nan * np.ones((N_trial, T), dtype=np.float)\n",
    "    models_former = np.nan * np.ones((N_trial, T), dtype=np.float)\n",
    "    models_latter = np.nan * np.ones((N_trial, T), dtype=np.float)\n",
    "    stats_complete = np.nan * np.ones((N_trial, T), dtype=np.float)\n",
    "    \n",
    "    for trial in range(scores.shape[0]):\n",
    "        n_change = 0  # number of changes so far.\n",
    "        for t in range(h, T-h):\n",
    "            alpha= (n_change+1/2) / (t+1+1)\n",
    "            m_estimated = idxes_all[trial, t]\n",
    "\n",
    "            # Lv.3 change (Model change)\n",
    "            stats_half_t = np.zeros((K, K), dtype=np.float)\n",
    "            for k1 in range(K):\n",
    "                stats_former = scores_f[trial, t, k1]\n",
    "                for k2 in range(K):\n",
    "                    if k1 == k2:\n",
    "                        p = 1.0 - alpha\n",
    "                    else:\n",
    "                        p = alpha/(K-1)\n",
    "                    stats_latter = scores_l[trial, t, k2]\n",
    "                    stats_half_t[k1, k2] = (stats_former + stats_latter) + codelens[k1] - np.log(p)\n",
    "            m_former_estimated, m_latter_estimated = np.unravel_index(np.nanargmin(stats_half_t), (K, K))\n",
    "            models_former[trial, t] = m_former_estimated\n",
    "            models_latter[trial, t] = m_latter_estimated\n",
    "            \n",
    "            stat = 0.5 / h *(scores[trial, t, m_estimated] + codelens[m_estimated] - stats_half_t[m_former_estimated, m_latter_estimated])\n",
    "            stats_complete[trial, t] = stat\n",
    "            \n",
    "            if (m_estimated == m_latter_estimated):\n",
    "                model_t = m_estimated\n",
    "            else:\n",
    "                model_t = m_latter_estimated\n",
    "                        \n",
    "            if t >= 1:\n",
    "                model_prev = models_estimated[trial, t-1]\n",
    "                if model_t != model_prev:\n",
    "                    n_change += 1            \n",
    "            models_estimated[trial, t] = model_t\n",
    "    \n",
    "    return stats_complete, models_estimated, models_former, models_latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats_with_modelidx(scores, scores_f, scores_l, idxes_model, idxes_model_f, idxes_model_l, h):\n",
    "    scores = np.array(scores)\n",
    "    scores_f = np.array(scores_f)\n",
    "    scores_l = np.array(scores_l)\n",
    "    \n",
    "    stats_complete = np.nan * np.ones((idxes_model.shape[0], idxes_model.shape[1]), dtype=np.float)\n",
    "    for trial in range(idxes_model.shape[0]):\n",
    "        for t in range(h, idxes_model.shape[1]-h):\n",
    "            stat = 0.5/h * (scores[trial, t, int(idxes_model[trial, t])] - \\\n",
    "                            (scores_f[trial, t, int(idxes_model_f[trial, t])] + \\\n",
    "                            scores_l[trial, t, int(idxes_model_l[trial, t])] ))\n",
    "            stats_complete[trial, t] = stat\n",
    "            \n",
    "    return stats_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codelen_integer(k):\n",
    "    codelen = np.log(2.865)\n",
    "    while k >= 0.0:\n",
    "        codelen += k\n",
    "        k = np.log(k)\n",
    "        \n",
    "    return codelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(indir, 'X_abrupt.pkl'), 'rb') as f:\n",
    "    X_all = pickle.load(f)\n",
    "with open(os.path.join(indir, 'Z_abrupt.pkl'), 'rb') as f:\n",
    "    Z_true_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 80, 100, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sbm_each_trial(X, trial, K, T):\n",
    "    pi_list_trial = []\n",
    "    theta_list_trial = []\n",
    "    z_list_trial = []\n",
    "    \n",
    "    for t in tqdm.tqdm(range(T)):\n",
    "        seed = trial * T + t\n",
    "        numpy2ri.activate()\n",
    "        sbm = blockmodels.BM_bernoulli(membership_type=\"SBM\", \n",
    "                                       adj=np.array(X[trial, t, :, :]),\n",
    "                                       verbosity=0,\n",
    "                                       exploration_factor=1.5,\n",
    "                                       explore_min=K,\n",
    "                                       explore_max=K)\n",
    "\n",
    "        estimate = dollar(sbm, \"estimate\")\n",
    "        estimate()\n",
    "\n",
    "        pi_list = []\n",
    "        theta_list = []\n",
    "        z_posterior_list = []\n",
    "        for k in range(K):\n",
    "            n_clusters = k + 1\n",
    "            theta = np.array(dollar(dollar(sbm, \"model_parameters\")[k], \"pi\"))\n",
    "            z_posterior = np.array(dollar(dollar(sbm, \"memberships\")[k], \"Z\"))\n",
    "            pi = np.sum(z_posterior, axis=0) + 10 * EPS\n",
    "            pi /= np.sum(pi)\n",
    "\n",
    "            theta_list.append(theta)\n",
    "            z_posterior_list.append(z_posterior)\n",
    "            pi_list.append(pi)\n",
    "\n",
    "        numpy2ri.deactivate()\n",
    "        \n",
    "        pi_list_trial.append(pi_list)\n",
    "        theta_list_trial.append(theta_list)\n",
    "        z_list_trial.append(z_posterior_list)\n",
    "\n",
    "    return pi_list_trial, theta_list_trial, z_list_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [07:59<1:11:58, 479.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [18:45<1:10:35, 529.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [27:29<1:01:36, 528.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [35:13<50:52, 508.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [43:11<41:38, 499.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [49:30<30:52, 463.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [57:37<23:31, 470.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [1:07:51<17:06, 513.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [1:18:07<09:04, 544.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:27:37<00:00, 525.79s/it]\n"
     ]
    }
   ],
   "source": [
    "EPS = np.finfo(np.float).eps\n",
    "\n",
    "N_trial = X_all.shape[0]\n",
    "T = X_all.shape[1]\n",
    "\n",
    "K = 10\n",
    "\n",
    "pi1 = None\n",
    "pi2 = None\n",
    "a0 = 1.0\n",
    "b0 = 1.0\n",
    "ratio = 0.02\n",
    "\n",
    "pi_all = []\n",
    "theta_all = []\n",
    "z_all = []\n",
    "\n",
    "for trial in tqdm.tqdm(range(N_trial)):\n",
    "    pi1 = None\n",
    "    pi2 = None\n",
    "    theta = None\n",
    "    \n",
    "    pi_list_trial = []\n",
    "    theta_list_trial = []\n",
    "    z_list_trial = []\n",
    "    \n",
    "    numpy2ri.activate()    \n",
    "    \n",
    "    for t in range(T):\n",
    "        seed = trial*T + t\n",
    "        \n",
    "        X = X_all[trial, t, :, :]\n",
    "            \n",
    "        sbm = blockmodels.BM_bernoulli(membership_type=\"SBM\", adj=np.array(X),\n",
    "                                           verbosity=0,\n",
    "                                           exploration_factor=1.5,\n",
    "                                           explore_min=K,\n",
    "                                           explore_max=K)\n",
    "\n",
    "        estimate = dollar(sbm, \"estimate\")\n",
    "        estimate()\n",
    "\n",
    "        theta_list = []\n",
    "        pi_list = []\n",
    "        z_posterior_list = []\n",
    "        for k in range(K):\n",
    "            n_clusters = k + 1\n",
    "            theta = np.array(dollar(dollar(sbm, \"model_parameters\")[k], \"pi\"))\n",
    "            z_posterior = np.array(dollar(dollar(sbm, \"memberships\")[k], \"Z\"))\n",
    "            pi = np.sum(z_posterior, axis=0) + 10 * EPS\n",
    "            pi /= np.sum(pi)\n",
    "\n",
    "            theta_list.append(theta)\n",
    "            z_posterior_list.append(z_posterior)\n",
    "            pi_list.append(pi)\n",
    "       \n",
    "        pi_list_trial.append(pi_list)\n",
    "        theta_list_trial.append(theta_list)\n",
    "        z_list_trial.append(z_posterior_list)\n",
    "        \n",
    "    numpy2ri.deactivate()\n",
    "\n",
    "    pi_all.append(pi_list_trial)\n",
    "    theta_all.append(theta_list_trial)\n",
    "    z_all.append(z_list_trial)\n",
    "\n",
    "    with open(os.path.join(outdir, 'pi_abrupt.pkl'), 'wb') as f:\n",
    "        pickle.dump(pi_all, f)\n",
    "    with open(os.path.join(outdir, 'theta_abrupt.pkl'), 'wb') as f:\n",
    "        pickle.dump(theta_all, f)\n",
    "    with open(os.path.join(outdir, 'z_abrupt.pkl'), 'wb') as f:\n",
    "        pickle.dump(z_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdir, 'pi_abrupt.pkl'), 'rb') as f:\n",
    "    pi_all = pickle.load(f)\n",
    "with open(os.path.join(outdir, 'theta_abrupt.pkl'), 'rb') as f:\n",
    "    theta_all = pickle.load(f)\n",
    "with open(os.path.join(outdir, 'z_abrupt.pkl'), 'rb') as f:\n",
    "    Z_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# relabeling\n",
    "N_trial = X_all.shape[0]\n",
    "K = 10\n",
    "T = X_all.shape[1]\n",
    "\n",
    "numpy2ri.activate()\n",
    "for trial in tqdm.tqdm(range(N_trial)):\n",
    "    for k in range(1, K):\n",
    "        run = label_switching.ecr_iterative_2(\n",
    "            z=np.vstack([\n",
    "                  np.argmax(Z_all[trial][t][k], axis=1).reshape(1, -1) for t in range(20)\n",
    "            ]) + 1,\n",
    "            K=k+1,\n",
    "            p=np.stack([Z_all[trial][t][k] for t in range(20)])\n",
    "        )\n",
    "        permutations = np.array(dollar(run, \"permutations\"))\n",
    "\n",
    "        for t in range(20):\n",
    "            Z_all[trial][t][k] = Z_all[trial][t][k][:, permutations[t, :]-1]\n",
    "\n",
    "        run = label_switching.ecr_iterative_2(\n",
    "            z=np.vstack([\n",
    "                  np.argmax(Z_all[trial][t][k], axis=1).reshape(1, -1) for t in range(19, 38)\n",
    "            ]) + 1,\n",
    "            K=k+1,\n",
    "            p=np.stack([Z_all[trial][t][k] for t in range(19, 38)])\n",
    "        )\n",
    "        permutations = np.array(dollar(run, \"permutations\"))\n",
    "\n",
    "        for i, t in enumerate(range(19, 38)):\n",
    "            if t == 19:\n",
    "                for tt in range(20):\n",
    "                    Z_all[trial][tt][k] = Z_all[trial][tt][k][:, permutations[i, :]-1]\n",
    "            else:\n",
    "                Z_all[trial][t][k] = Z_all[trial][t][k][:, permutations[i, :]-1]\n",
    "        \n",
    "        run = label_switching.ecr_iterative_2(\n",
    "            z=np.vstack([\n",
    "                  np.argmax(Z_all[trial][t][k], axis=1).reshape(1, -1) for t in range(37, 41)\n",
    "            ]) + 1,\n",
    "            K=k+1,\n",
    "            p=np.stack([Z_all[trial][t][k] for t in range(37, 41)])\n",
    "        )        \n",
    "        permutations = np.array(dollar(run, \"permutations\"))\n",
    "        \n",
    "        for i, t in enumerate(range(37, 41)):\n",
    "            if t == 37:\n",
    "                for tt in range(38):\n",
    "                    Z_all[trial][tt][k] = Z_all[trial][tt][k][:, permutations[i, :]-1]\n",
    "            else:\n",
    "                Z_all[trial][t][k] = Z_all[trial][t][k][:, permutations[i, :]-1]\n",
    "\n",
    "        run = label_switching.ecr_iterative_2(\n",
    "            z=np.vstack([\n",
    "                  np.argmax(Z_all[trial][t][k], axis=1).reshape(1, -1) for t in range(40, 58)\n",
    "            ]) + 1,\n",
    "            K=k+1,\n",
    "            p=np.stack([Z_all[trial][t][k] for t in range(40, 58)])\n",
    "        )\n",
    "        permutations = np.array(dollar(run, \"permutations\"))\n",
    "        \n",
    "        for i, t in enumerate(range(40, 58)):\n",
    "            if t == 40:\n",
    "                for tt in range(41):\n",
    "                    Z_all[trial][tt][k] = Z_all[trial][tt][k][:, permutations[i, :]-1]\n",
    "            else:\n",
    "                Z_all[trial][t][k] = Z_all[trial][t][k][:, permutations[i, :]-1]\n",
    "\n",
    "        run = label_switching.ecr_iterative_2(\n",
    "            z=np.vstack([\n",
    "                  np.argmax(Z_all[trial][t][k], axis=1).reshape(1, -1) for t in range(57, 61)\n",
    "            ]) + 1,\n",
    "            K=k+1,\n",
    "            p=np.stack([Z_all[trial][t][k] for t in range(57, 61)])\n",
    "        )\n",
    "        permutations = np.array(dollar(run, \"permutations\"))\n",
    "\n",
    "        for i, t in enumerate(range(57, 61)):\n",
    "            if t == 57:\n",
    "                for tt in range(58):\n",
    "                    Z_all[trial][tt][k] = Z_all[trial][tt][k][:, permutations[i, :]-1]\n",
    "            else:\n",
    "                Z_all[trial][t][k] = Z_all[trial][t][k][:, permutations[i, :]-1]\n",
    "\n",
    "        run = label_switching.ecr_iterative_2(\n",
    "            z=np.vstack([\n",
    "                  np.argmax(Z_all[trial][t][k], axis=1).reshape(1, -1) for t in range(60, 80)\n",
    "            ]) + 1,\n",
    "            K=k+1,\n",
    "            p=np.stack([Z_all[trial][t][k] for t in range(60, 80)])\n",
    "        )        \n",
    "\n",
    "        permutations = np.array(dollar(run, \"permutations\"))\n",
    "        for i, t in enumerate(range(60, 80)):\n",
    "            if t == 60:\n",
    "                for tt in range(61):\n",
    "                    Z_all[trial][tt][k] = Z_all[trial][tt][k][:, permutations[i, :]-1]\n",
    "            else:\n",
    "                Z_all[trial][t][k] = Z_all[trial][t][k][:, permutations[i, :]-1]\n",
    "\n",
    "numpy2ri.deactivate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdir, 'z_abrupt.pkl'), 'wb') as f:\n",
    "    pickle.dump(Z_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sc(X_array, Z_array, K, L):\n",
    "    T = X_array.shape[0]\n",
    "    N = X_array.shape[1]\n",
    "    \n",
    "    print('T = %d' % (T))\n",
    "    \n",
    "    logp = 0.0\n",
    "    for k in range(K):\n",
    "        for l in range(L):\n",
    "            n_T = np.zeros(T, dtype=np.int)\n",
    "            for t in range(T):\n",
    "                n_k = np.sum(Z_array[t, :] == k)\n",
    "                n_l = np.sum(Z_array[t, :] == l)\n",
    "                n_T[t] = n_k * n_l\n",
    "\n",
    "            for n in tqdm.tqdm(product(*[np.arange(n_T[t]+1) for t in range(T)])):\n",
    "                for t in range(T):\n",
    "                    logp += loggamma(N+1) - loggamma(n[t]+1) - loggamma(N -n[t]+1)\n",
    "                n_all = np.sum(n_T)\n",
    "                n_pos = np.sum(n)\n",
    "                n_neg = n_all - n_pos\n",
    "                logp += -n_pos * (np.log(n_pos) - np.log(n_all)) - n_neg * (np.log(n_neg) - np.log(n_all))\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/Users/shi-fukushima/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/shi-fukushima/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/shi-fukushima/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "\n",
      " 10%|█         | 1/10 [00:22<03:22, 22.46s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:45<03:00, 22.60s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:05<02:34, 22.00s/it]\u001b[A\n",
      " 40%|████      | 4/10 [01:20<01:58, 19.75s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [01:39<01:37, 19.53s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [01:57<01:15, 18.95s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [02:18<00:58, 19.56s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [02:36<00:38, 19.30s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [02:56<00:19, 19.43s/it]\u001b[A\n",
      "100%|██████████| 10/10 [03:14<00:00, 19.46s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:14<06:29, 194.65s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:30<04:36, 30.71s/it]\u001b[A\n",
      " 20%|██        | 2/10 [01:07<04:19, 32.45s/it]\u001b[A\n",
      " 30%|███       | 3/10 [01:44<03:56, 33.76s/it]\u001b[A\n",
      " 40%|████      | 4/10 [02:16<03:20, 33.44s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [02:52<02:49, 33.99s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [03:31<02:22, 35.61s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [04:24<02:02, 40.83s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [05:14<01:27, 43.52s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [06:01<00:44, 44.62s/it]\u001b[A\n",
      "100%|██████████| 10/10 [06:46<00:00, 40.65s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [10:01<04:18, 258.20s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:59<08:59, 59.98s/it]\u001b[A\n",
      " 20%|██        | 2/10 [02:12<08:29, 63.71s/it]\u001b[A\n",
      " 30%|███       | 3/10 [03:28<07:51, 67.31s/it]\u001b[A\n",
      " 40%|████      | 4/10 [04:28<06:31, 65.24s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [05:40<05:35, 67.17s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [06:42<04:22, 65.62s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [07:53<03:22, 67.40s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [09:10<02:20, 70.33s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [10:27<01:12, 72.28s/it]\u001b[A\n",
      "100%|██████████| 10/10 [11:41<00:00, 70.14s/it]\u001b[A\n",
      "100%|██████████| 3/3 [21:42<00:00, 434.19s/it]\n"
     ]
    }
   ],
   "source": [
    "n_trial = X_all.shape[0]\n",
    "T = X_all.shape[1]\n",
    "K = 10\n",
    "\n",
    "for h in tqdm.tqdm([1, 2, 3]):\n",
    "    dnml_whole_list, nml_x_z_whole_list, nml_z_whole_list = \\\n",
    "        np.nan * np.ones((n_trial, T, K)), np.nan * np.ones((n_trial, T, K)), np.nan * np.ones((n_trial, T, K))\n",
    "    dnml_former_list, nml_x_z_former_list, nml_z_former_list = \\\n",
    "        np.nan * np.ones((n_trial, T, K)), np.nan * np.ones((n_trial, T, K)), np.nan * np.ones((n_trial, T, K))\n",
    "    dnml_latter_list, nml_x_z_latter_list, nml_z_latter_list = \\\n",
    "        np.nan * np.ones((n_trial, T, K)), np.nan * np.ones((n_trial, T, K)), np.nan * np.ones((n_trial, T, K))\n",
    "    \n",
    "    theta_hat_whole_list_k3, theta_hat_former_list_k3, theta_hat_latter_list_k3 = \\\n",
    "        np.nan * np.ones((n_trial, T, 3, 3)), np.nan * np.ones((n_trial, T, 3, 3)), np.nan * np.ones((n_trial, T, 3, 3))\n",
    "    \n",
    "    theta_hat_whole_list_k4, theta_hat_former_list_k4, theta_hat_latter_list_k4 = \\\n",
    "        np.nan * np.ones((n_trial, T, 4, 4)), np.nan * np.ones((n_trial, T, 4, 4)), np.nan * np.ones((n_trial, T, 4, 4))\n",
    "\n",
    "    \n",
    "    for trial in tqdm.tqdm(range(n_trial)):\n",
    "        for t in range(h, T-h):\n",
    "            for k in range(K):\n",
    "                t_start = t-h\n",
    "                t_end = t+h\n",
    "\n",
    "                # whole\n",
    "                n_whole = np.sum([[np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == v) for v in range(k+1)] \n",
    "                                  for tt in range(t_start, t_end)], axis=0)\n",
    "\n",
    "                theta_hat_whole = np.sum(\n",
    "                        [[[np.sum(X_all[trial][tt][np.argmax(Z_all[trial][tt][k], axis=1) == k1, :][:, np.argmax(Z_all[trial][tt][k], axis=1) == k2])\n",
    "                           for k2 in range(k+1)] for k1 in range(k+1)] \n",
    "                           for tt in range(t_start, t_end)], axis=0) / \\\n",
    "                        np.sum(\n",
    "                            [[[np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == k1) * np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == k2) \n",
    "                            for k2 in range(k+1)] for k1 in range(k+1)] \n",
    "                            for tt in range(t_start, t_end)], axis=0)\n",
    "\n",
    "                theta_hat_whole = theta_hat_whole[n_whole !=0, :][:, n_whole !=0]\n",
    "                pi_hat_whole = n_whole[n_whole !=0] /np.sum(n_whole)\n",
    "\n",
    "                n_cluster_whole = len(pi_hat_whole)\n",
    "\n",
    "                res_w = np.array([calc_dnml_by_prob(X_all[trial, tt, :, :], \n",
    "                                                    Z_all[trial][tt][k], \n",
    "                                                    pi_hat_whole, theta_hat_whole,\n",
    "                                                    n_cluster_whole, n_cluster_whole) \n",
    "                                  for tt in range(t_start, t_end)])\n",
    "\n",
    "                dnml_whole = np.sum(res_w[:, 0])\n",
    "                nml_x_z_whole = np.sum(res_w[:, 1])\n",
    "                nml_z_whole = np.sum(res_w[:, 2])\n",
    "\n",
    "                val = dnml_whole_list[trial, t, n_cluster_whole-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (dnml_whole < val) )):\n",
    "                    dnml_whole_list[trial, t, n_cluster_whole-1] = dnml_whole\n",
    "                    \n",
    "                val = nml_x_z_whole_list[trial, t, n_cluster_whole-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (nml_x_z_whole < val) )):\n",
    "                    nml_x_z_whole_list[trial, t, n_cluster_whole-1] = nml_x_z_whole\n",
    "                    \n",
    "                val = nml_z_whole_list[trial, t, n_cluster_whole-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (nml_z_whole < val) )):\n",
    "                    nml_z_whole_list[trial, t, n_cluster_whole-1] = nml_z_whole\n",
    "                                    \n",
    "                # former\n",
    "                n_former = np.sum([[np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == v) for v in range(k+1)] \n",
    "                                   for tt in range(t_start, t_start+h)], axis=0)\n",
    "\n",
    "                theta_hat_former = np.sum(\n",
    "                        [[[np.sum(X_all[trial][tt][np.argmax(Z_all[trial][tt][k], axis=1) == k1, :][:, np.argmax(Z_all[trial][tt][k], axis=1) == k2])\n",
    "                            for k2 in range(k+1)] for k1 in range(k+1)] \n",
    "                         for tt in range(t_start, t_start+h)], axis=0) / \\\n",
    "                        np.sum(\n",
    "                            [[[np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == k1) * np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == k2) \n",
    "                            for k2 in range(k+1)] for k1 in range(k+1)]\n",
    "                            for tt in range(t_start, t_start+h)], axis=0)\n",
    "\n",
    "                theta_hat_former = theta_hat_former[n_former !=0, :][:, n_former !=0]\n",
    "                pi_hat_former = n_former[n_former !=0] /np.sum(n_former)\n",
    "\n",
    "                n_cluster_former = len(pi_hat_former)\n",
    "\n",
    "                res_f = np.array([calc_dnml_by_prob(X_all[trial, tt, :, :], \n",
    "                                                    Z_all[trial][tt][k], \n",
    "                                                    pi_hat_former, theta_hat_former,\n",
    "                                                    n_cluster_former, n_cluster_former) \n",
    "                                  for tt in range(t_start, t_start+h)])\n",
    "\n",
    "                dnml_former = np.sum(res_f[:, 0])\n",
    "                nml_x_z_former = np.sum(res_f[:, 1])\n",
    "                nml_z_former = np.sum(res_f[:, 2])\n",
    "\n",
    "                val = dnml_former_list[trial, t, n_cluster_former-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (dnml_former < val) )):\n",
    "                    dnml_former_list[trial, t, n_cluster_former-1] = dnml_former\n",
    "\n",
    "                val = nml_x_z_former_list[trial, t, n_cluster_former-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (nml_x_z_former < val) )):\n",
    "                    nml_x_z_former_list[trial, t, n_cluster_former-1] = nml_x_z_former\n",
    "                    \n",
    "                val = nml_z_former_list[trial, t, n_cluster_former-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (nml_z_former < val) )):\n",
    "                    nml_z_former_list[trial, t, n_cluster_former-1] = nml_z_former\n",
    "\n",
    "                # latter\n",
    "                n_latter = np.sum([[np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == v) for v in range(k+1)]\n",
    "                                   for tt in range(t_start+h, t_end)], axis=0)\n",
    "\n",
    "                theta_hat_latter = np.sum(\n",
    "                         [[[np.sum(X_all[trial][tt][np.argmax(Z_all[trial][tt][k], axis=1) == k1, :][:, np.argmax(Z_all[trial][tt][k], axis=1) == k2])\n",
    "                            for k2 in range(k+1)] for k1 in range(k+1)] for tt in range(t_start+h, t_end)], axis=0) / \\\n",
    "                        np.sum(\n",
    "                         [[[np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == k1) * np.sum(np.argmax(Z_all[trial][tt][k], axis=1) == k2) \n",
    "                            for k2 in range(k+1)] for k1 in range(k+1)] for tt in range(t_start+h, t_end)], axis=0)\n",
    "\n",
    "                theta_hat_latter = theta_hat_latter[n_latter != 0, :][:, n_latter !=0]\n",
    "                pi_hat_latter = n_latter[n_latter != 0] /np.sum(n_latter)\n",
    "\n",
    "                n_cluster_latter = len(pi_hat_latter)\n",
    "                res_l = np.array([calc_dnml_by_prob(X_all[trial, tt, :, :], \n",
    "                                                    Z_all[trial][tt][k], \n",
    "                                                    pi_hat_latter, theta_hat_latter,\n",
    "                                                    n_cluster_latter, n_cluster_latter) for tt in range(t_start+h, t_end)])\n",
    "\n",
    "                dnml_latter = np.sum(res_l[:, 0])\n",
    "                nml_x_z_latter = np.sum(res_l[:, 1])\n",
    "                nml_z_latter = np.sum(res_l[:, 2])\n",
    "\n",
    "                val = dnml_latter_list[trial, t, n_cluster_latter-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (dnml_latter < val) )):\n",
    "                    dnml_latter_list[trial, t, n_cluster_latter-1] = dnml_latter\n",
    "\n",
    "                val = nml_x_z_latter_list[trial, t, n_cluster_latter-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (nml_x_z_latter < val) )):\n",
    "                    nml_x_z_latter_list[trial, t, n_cluster_latter-1] = nml_x_z_latter\n",
    "                    \n",
    "                val = nml_z_whole_list[trial, t, n_cluster_latter-1]\n",
    "                if (np.isnan(val) | ( (np.isfinite(val)) & (nml_z_latter < val) )):\n",
    "                    nml_z_latter_list[trial, t, n_cluster_latter-1] = nml_z_latter\n",
    "                \n",
    "    with open(os.path.join(outdir, 'dnml_all_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(dnml_whole_list, f)\n",
    "    with open(os.path.join(outdir, 'dnml_f_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(dnml_former_list, f)\n",
    "    with open(os.path.join(outdir, 'dnml_l_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(dnml_latter_list, f)\n",
    "\n",
    "    with open(os.path.join(outdir, 'nml_x_z_all_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(nml_x_z_whole_list, f)\n",
    "    with open(os.path.join(outdir, 'nml_x_z_f_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(nml_x_z_former_list, f)\n",
    "    with open(os.path.join(outdir, 'nml_x_z_l_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(nml_x_z_latter_list, f)\n",
    "\n",
    "    with open(os.path.join(outdir, 'nml_z_all_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(nml_z_whole_list, f)\n",
    "    with open(os.path.join(outdir, 'nml_z_f_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(nml_z_former_list, f)\n",
    "    with open(os.path.join(outdir, 'nml_z_l_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(nml_z_latter_list, f)\n",
    "\n",
    "    with open(os.path.join(outdir, 'theta_hat_all_k3_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(theta_hat_whole_list_k3, f)\n",
    "    with open(os.path.join(outdir, 'theta_hat_former_k3_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(theta_hat_former_list_k3, f)\n",
    "    with open(os.path.join(outdir, 'theta_hat_latter_k3_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(theta_hat_latter_list_k3, f)\n",
    "\n",
    "    with open(os.path.join(outdir, 'theta_hat_all_k4_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(theta_hat_whole_list_k4, f)\n",
    "    with open(os.path.join(outdir, 'theta_hat_former_k4_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(theta_hat_former_list_k4, f)\n",
    "    with open(os.path.join(outdir, 'theta_hat_latter_k4_h' + str(h) + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(theta_hat_latter_list_k4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
